{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import transform as t\n",
    "import resample as r\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics, linear_model, svm, ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crie os seguintes arquivos com extensão .py e implemente os métodos definidos para cada um deles:\n",
    "    transform.py\n",
    "        standardize\n",
    "        normalize\n",
    "    resample.py\n",
    "        split_k_fold(n_elem, n_splits=3, shuffle=True, seed=0)\n",
    "            n_elem - número total de elementos.\n",
    "            n_split - número de folds. Mínimo: 2.\n",
    "            shuffle - aleatoriza a ordem dos dados (True) ou não (False).\n",
    "            seed - determina uma semente para geração de números aleatórios ou não (None).\n",
    "\n",
    "            Retorno: 2 arrays (idx_train e idx_test), cada um com n_splits elementos: \n",
    "                Exemplo para n_splits=3, teremos idx_train[0], idx_train[1] e idx_train[2].\n",
    "                Exemplo para n_splits=3, teremos idx_test[0], idx_test[1] e idx_test[2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.46385011, -0.87831007, -0.29277002,  0.29277002,  0.87831007,\n",
       "         1.46385011]), array([ 0. ,  0.2,  0.4,  0.6,  0.8,  1. ]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTE\n",
    "X = np.array([0,1,2,3,4,5])\n",
    "X_std = t.standarlize(X)\n",
    "X_norm = t.normalize(X)\n",
    "\n",
    "X_std, X_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TESTE 2\n",
    "#idx_treino, idx_teste = r.split_k_fold(len(X), 5, True, 0)\n",
    "\n",
    "#idx_treino, idx_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Use sua implementação de split_k_fold a fim de fazer Cross Validation com k=5 (5-Fold) para obter o MSE de regressões para o seguinte dataset sobre a qualidade de vinhos tintos (winequality-red.csv). Compare as seguintes técnicas de regressão (pode usar as implementações do Scikit Learn):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1599, 12), 5, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTE\n",
    "\n",
    "data = np.genfromtxt(\"winequality-red.csv\", delimiter=\";\", skip_header=1)\n",
    "\n",
    "idx_train, idx_test = r.split_k_fold(data.shape[0], 5, True, 0)\n",
    "\n",
    "data.shape, len(idx_train), len(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FORMATANDO OS DADOS PARA AS CRIAÇÔES DOS MODELOS\n",
    "\n",
    "X = data[:, 0]\n",
    "y = data[:, 1]\n",
    "\n",
    "X_f = [[i] for i in X]\n",
    "y_f = [[i] for i in y]\n",
    "\n",
    "Xtrain = []\n",
    "ytrain = []\n",
    "Xtest = []\n",
    "ytest = []\n",
    "\n",
    "for i in range(len(idx_train)):\n",
    "    Xtrain.append(X[idx_train[i]])\n",
    "    ytrain.append(y[idx_train[i]])\n",
    "\n",
    "for i in range(len(idx_test)):\n",
    "    Xtest.append(X[idx_test[i]])\n",
    "    ytest.append(y[idx_test[i]])\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(len(Xtrain)):\n",
    "    X_train.append([[i] for i in Xtrain[i]])\n",
    "    y_train.append([[i] for i in ytrain[i]])\n",
    "\n",
    "for i in range(len(Xtest)):\n",
    "    X_test.append([[i] for i in Xtest[i]])\n",
    "    y_test.append([[i] for i in ytest[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD - Stochastic Gradient Descent Regressor\n",
    "(http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD --> MSE = 0.044315320602397734\n"
     ]
    }
   ],
   "source": [
    "# MODELO DO 0\n",
    "modelSGD_0 = linear_model.SGDRegressor()\n",
    "modelSGD_0.fit(X_train[0], y_train[0])\n",
    "y1_pred_0 = modelSGD_0.predict(X_test[0])\n",
    "mse1_0 = metrics.mean_squared_error(y_test[0], y1_pred_0)\n",
    "#score1_0 = modelSGD_0.score(X_test[0], y_test[0])  \n",
    "\n",
    "# MODELO DO 1\n",
    "modelSGD_1 = linear_model.SGDRegressor()\n",
    "modelSGD_1.fit(X_train[1], y_train[1])\n",
    "y1_pred_1 = modelSGD_1.predict(X_test[1])\n",
    "mse1_1 = metrics.mean_squared_error(y_test[1], y1_pred_1)\n",
    "#score1_1 = modelSGD_1.score(X_test[1], y_test[1])\n",
    "\n",
    "# MODELO DO 2\n",
    "modelSGD_2 = linear_model.SGDRegressor()\n",
    "modelSGD_2.fit(X_train[2], y_train[2])\n",
    "y1_pred_2 = modelSGD_2.predict(X_test[2])\n",
    "mse1_2 = metrics.mean_squared_error(y_test[2], y1_pred_2)\n",
    "#score1_2 = modelSGD_2.score(X_test[2], y_test[2])\n",
    "\n",
    "# MODELO DO 3\n",
    "modelSGD_3 = linear_model.SGDRegressor()\n",
    "modelSGD_3.fit(X_train[3], y_train[3])\n",
    "y1_pred_3 = modelSGD_3.predict(X_test[3])\n",
    "mse1_3 = metrics.mean_squared_error(y_test[3], y1_pred_3)\n",
    "#score1_3 = modelSGD_3.score(X_test[3], y_test[3])\n",
    "\n",
    "# MODELO DO 4\n",
    "modelSGD_4 = linear_model.SGDRegressor()\n",
    "modelSGD_4.fit(X_train[4], y_train[4])\n",
    "y1_pred_4 = modelSGD_4.predict(X_test[4])\n",
    "mse1_4 = metrics.mean_squared_error(y_test[4], y1_pred_4)\n",
    "#score1_4 = modelSGD_4.score(X_test[4], y_test[4])\n",
    "\n",
    "mseSGD = (mse1_0 + mse1_1 + mse1_2 + mse1_3 + mse1_4) / 5\n",
    "#scoreSGD = (score1_0 + score1_1 + score1_2 + score1_3 + score1_4) / 5\n",
    "\n",
    "print(\"SGD --> MSE = {}\".format(mseSGD))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "(http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR --> MSE = 0.02993049703495957\n"
     ]
    }
   ],
   "source": [
    "# MODELO DO 0\n",
    "modelLR_0 = linear_model.LinearRegression()\n",
    "modelLR_0.fit(X_train[0], y_train[0])\n",
    "y2_pred_0 = modelLR_0.predict(X_test[0])\n",
    "mse2_0 = metrics.mean_squared_error(y_test[0], y2_pred_0)\n",
    "#score2_0 = modelLR_0.score(X_test[0], y_test[0])\n",
    "\n",
    "# MODELO DO 1\n",
    "modelLR_1 = linear_model.LinearRegression()\n",
    "modelLR_1.fit(X_train[1], y_train[1])\n",
    "y2_pred_1 = modelLR_1.predict(X_test[1])\n",
    "mse2_1 = metrics.mean_squared_error(y_test[1], y2_pred_1)\n",
    "#score2_1 = modelLR_1.score(X_test[1], y_test[1])\n",
    "\n",
    "# MODELO DO 2\n",
    "modelLR_2 = linear_model.LinearRegression()\n",
    "modelLR_2.fit(X_train[2], y_train[2])\n",
    "y2_pred_2 = modelLR_2.predict(X_test[2])\n",
    "mse2_2 = metrics.mean_squared_error(y_test[2], y2_pred_2)\n",
    "#score2_2 = modelLR_2.score(X_test[2], y_test[2])\n",
    "\n",
    "# MODELO DO 3\n",
    "modelLR_3 = linear_model.LinearRegression()\n",
    "modelLR_3.fit(X_train[3], y_train[3])\n",
    "y2_pred_3 = modelLR_3.predict(X_test[3])\n",
    "mse2_3 = metrics.mean_squared_error(y_test[3], y2_pred_3)\n",
    "#score2_3 = modelLR_3.score(X_test[3], y_test[3])\n",
    "\n",
    "# MODELO DO 4\n",
    "modelLR_4 = linear_model.LinearRegression()\n",
    "modelLR_4.fit(X_train[4], y_train[4])\n",
    "y2_pred_4 = modelLR_4.predict(X_test[4])\n",
    "mse2_4 = metrics.mean_squared_error(y_test[4], y2_pred_4)\n",
    "#score2_4 = modelLR_4.score(X_test[4], y_test[4])\n",
    "\n",
    "mseLR = (mse2_0 + mse2_1 + mse2_2 + mse2_3 + mse2_4) / 5\n",
    "#scoreLR = (score2_0 + score2_1 + score2_2 + score2_3 + score2_4) / 5\n",
    "\n",
    "print(\"LR --> MSE = {}\".format(mseLR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVR\n",
    "(http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html#sklearn.svm.LinearSVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSVR --> MSE = 0.031702333287014196\n"
     ]
    }
   ],
   "source": [
    "# MODELO DO 0\n",
    "modelLSVR_0 = svm.LinearSVR()\n",
    "modelLSVR_0.fit(X_train[0], y_train[0])\n",
    "y3_pred_0 = modelLSVR_0.predict(X_test[0])\n",
    "mse3_0 = metrics.mean_squared_error(y_test[0], y3_pred_0)\n",
    "#score3_0 = modelLSVR_0.score(X_test[0], y_test[0])\n",
    "\n",
    "# MODELO DO 1\n",
    "modelLSVR_1 = svm.LinearSVR()\n",
    "modelLSVR_1.fit(X_train[1], y_train[1])\n",
    "y3_pred_1 = modelLSVR_1.predict(X_test[1])\n",
    "mse3_1 = metrics.mean_squared_error(y_test[1], y3_pred_1)\n",
    "#score3_1 = modelLSVR_1.score(X_test[1], y_test[1])\n",
    "\n",
    "# MODELO DO 2\n",
    "modelLSVR_2 = svm.LinearSVR()\n",
    "modelLSVR_2.fit(X_train[2], y_train[2])\n",
    "y3_pred_2 = modelLSVR_2.predict(X_test[2])\n",
    "mse3_2 = metrics.mean_squared_error(y_test[2], y3_pred_2)\n",
    "#score3_2 = modelLSVR_2.score(X_test[2], y_test[2])\n",
    "\n",
    "# MODELO DO 3\n",
    "modelLSVR_3 = svm.LinearSVR()\n",
    "modelLSVR_3.fit(X_train[3], y_train[3])\n",
    "y3_pred_3 = modelLSVR_3.predict(X_test[3])\n",
    "mse3_3 = metrics.mean_squared_error(y_test[3], y3_pred_3)\n",
    "#score3_3 = modelLSVR_3.score(X_test[3], y_test[3])\n",
    "\n",
    "# MODELO DO 4\n",
    "modelLSVR_4 = svm.LinearSVR()\n",
    "modelLSVR_4.fit(X_train[4], y_train[4])\n",
    "y3_pred_4 = modelLSVR_4.predict(X_test[4])\n",
    "mse3_4 = metrics.mean_squared_error(y_test[4], y3_pred_4)\n",
    "#score3_4 = modelLSVR_4.score(X_test[4], y_test[4])\n",
    "\n",
    "mseLSVR = (mse3_0 + mse3_1 + mse3_2 + mse3_3 + mse3_4) / 5\n",
    "#scoreLSVR = (score3_0 + score3_1 + score3_2 + score3_3 + score3_4) / 5\n",
    "\n",
    "print(\"LSVR --> MSE = {}\".format(mseLSVR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR - Epsilon-Support Vector Regression\n",
    "(http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR --> MSE = 0.029742411488478983\n"
     ]
    }
   ],
   "source": [
    "# MODELO DO 0\n",
    "modelSVR_0 = svm.SVR()\n",
    "modelSVR_0.fit(X_train[0], y_train[0])\n",
    "y4_pred_0 = modelSVR_0.predict(X_test[0])\n",
    "mse4_0 = metrics.mean_squared_error(y_test[0], y4_pred_0)\n",
    "#score4_0 = modelSVR_0.score(X_test[0], y_test[0])\n",
    "\n",
    "# MODELO DO 1\n",
    "modelSVR_1 = svm.SVR()\n",
    "modelSVR_1.fit(X_train[1], y_train[1])\n",
    "y4_pred_1 = modelSVR_1.predict(X_test[1])\n",
    "mse4_1 = metrics.mean_squared_error(y_test[1], y4_pred_1)\n",
    "#score4_1 = modelSVR_1.score(X_test[1], y_test[1])\n",
    "\n",
    "# MODELO DO 2\n",
    "modelSVR_2 = svm.SVR()\n",
    "modelSVR_2.fit(X_train[2], y_train[2])\n",
    "y4_pred_2 = modelSVR_2.predict(X_test[2])\n",
    "mse4_2 = metrics.mean_squared_error(y_test[2], y4_pred_2)\n",
    "#score4_2 = modelSVR_2.score(X_test[2], y_test[2])\n",
    "\n",
    "# MODELO DO 3\n",
    "modelSVR_3 = svm.SVR()\n",
    "modelSVR_3.fit(X_train[3], y_train[3])\n",
    "y4_pred_3 = modelSVR_3.predict(X_test[3])\n",
    "mse4_3 = metrics.mean_squared_error(y_test[3], y4_pred_3)\n",
    "#score4_3 = modelSVR_3.score(X_test[3], y_test[3])\n",
    "\n",
    "# MODELO DO 4\n",
    "modelSVR_4 = svm.SVR()\n",
    "modelSVR_4.fit(X_train[4], y_train[4])\n",
    "y4_pred_4 = modelSVR_4.predict(X_test[4])\n",
    "mse4_4 = metrics.mean_squared_error(y_test[4], y4_pred_4)\n",
    "#score4_4 = modelSVR_4.score(X_test[4], y_test[4])\n",
    "\n",
    "mseSVR = (mse4_0 + mse4_1 + mse4_2 + mse4_3 + mse4_4) / 5\n",
    "#scoreSVR = (score4_0 + score4_1 + score4_2 + score4_3 + score4_4) / 5\n",
    "\n",
    "print(\"SVR --> MSE = {}\".format(mseSVR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor \n",
    "(http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFR --> MSE = 0.030161102997754857\n"
     ]
    }
   ],
   "source": [
    "# MODELO DO 0\n",
    "modelRFR_0 = ensemble.RandomForestRegressor()\n",
    "modelRFR_0.fit(X_train[0], y_train[0])\n",
    "y5_pred_0 = modelRFR_0.predict(X_test[0])\n",
    "mse5_0 = metrics.mean_squared_error(y_test[0], y5_pred_0)\n",
    "#score5_0 = modelRFR_0.score(X_test[0], y_test[0])\n",
    "\n",
    "# MODELO DO 1\n",
    "modelRFR_1 = ensemble.RandomForestRegressor()\n",
    "modelRFR_1.fit(X_train[1], y_train[1])\n",
    "y5_pred_1 = modelRFR_1.predict(X_test[1])\n",
    "mse5_1 = metrics.mean_squared_error(y_test[1], y5_pred_1)\n",
    "#score5_1 = modelRFR_1.score(X_test[1], y_test[1])\n",
    "\n",
    "# MODELO DO 2\n",
    "modelRFR_2 = ensemble.RandomForestRegressor()\n",
    "modelRFR_2.fit(X_train[2], y_train[2])\n",
    "y5_pred_2 = modelRFR_2.predict(X_test[2])\n",
    "mse5_2 = metrics.mean_squared_error(y_test[2], y5_pred_2)\n",
    "#score5_2 = modelRFR_2.score(X_test[2], y_test[2])\n",
    "\n",
    "# MODELO DO 3\n",
    "modelRFR_3 = ensemble.RandomForestRegressor()\n",
    "modelRFR_3.fit(X_train[3], y_train[3])\n",
    "y5_pred_3 = modelRFR_3.predict(X_test[3])\n",
    "mse5_3 = metrics.mean_squared_error(y_test[3], y5_pred_3)\n",
    "#score5_3 = modelRFR_3.score(X_test[3], y_test[3])\n",
    "\n",
    "# MODELO DO 4\n",
    "modelRFR_4 = ensemble.RandomForestRegressor()\n",
    "modelRFR_4.fit(X_train[4], y_train[4])\n",
    "y5_pred_4 = modelRFR_4.predict(X_test[4])\n",
    "mse5_4 = metrics.mean_squared_error(y_test[4], y5_pred_4)\n",
    "#score5_4 = modelRFR_4.score(X_test[4], y_test[4])\n",
    "\n",
    "mseRFR = (mse5_0 + mse5_1 + mse5_2 + mse5_3 + mse5_4) / 5\n",
    "#scoreRFR = (score5_0 + score5_1 + score5_2 + score5_3 + score5_4) / 5\n",
    "\n",
    "print(\"RFR --> MSE = {}\".format(mseRFR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor \n",
    "(http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBR --> MSE = 0.029402170965826896\n"
     ]
    }
   ],
   "source": [
    "# MODELO DO 0\n",
    "modelGBR_0 = ensemble.GradientBoostingRegressor()\n",
    "modelGBR_0.fit(X_train[0], y_train[0])\n",
    "y6_pred_0 = modelGBR_0.predict(X_test[0])\n",
    "mse6_0 = metrics.mean_squared_error(y_test[0], y6_pred_0)\n",
    "#score6_0 = modelGBR_0.score(X_test[0], y_test[0])\n",
    "\n",
    "# MODELO DO 1\n",
    "modelGBR_1 = ensemble.GradientBoostingRegressor()\n",
    "modelGBR_1.fit(X_train[1], y_train[1])\n",
    "y6_pred_1 = modelGBR_1.predict(X_test[1])\n",
    "mse6_1 = metrics.mean_squared_error(y_test[1], y6_pred_1)\n",
    "#score6_1 = modelGBR_1.score(X_test[1], y_test[1])\n",
    "\n",
    "# MODELO DO 2\n",
    "modelGBR_2 = ensemble.GradientBoostingRegressor()\n",
    "modelGBR_2.fit(X_train[2], y_train[2])\n",
    "y6_pred_2 = modelGBR_2.predict(X_test[2])\n",
    "mse6_2 = metrics.mean_squared_error(y_test[2], y6_pred_2)\n",
    "#score6_2 = modelGBR_2.score(X_test[2], y_test[2])\n",
    "\n",
    "# MODELO DO 3\n",
    "modelGBR_3 = ensemble.GradientBoostingRegressor()\n",
    "modelGBR_3.fit(X_train[3], y_train[3])\n",
    "y6_pred_3 = modelGBR_3.predict(X_test[3])\n",
    "mse6_3 = metrics.mean_squared_error(y_test[3], y6_pred_3)\n",
    "#score6_3 = modelGBR_3.score(X_test[3], y_test[3])\n",
    "\n",
    "# MODELO DO 4\n",
    "modelGBR_4 = ensemble.GradientBoostingRegressor()\n",
    "modelGBR_4.fit(X_train[4], y_train[4])\n",
    "y6_pred_4 = modelGBR_4.predict(X_test[4])\n",
    "mse6_4 = metrics.mean_squared_error(y_test[4], y6_pred_4)\n",
    "#score6_4 = modelGBR_4.score(X_test[4], y_test[4])\n",
    "\n",
    "mseGBR = (mse6_0 + mse6_1 + mse6_2 + mse6_3 + mse6_4) / 5\n",
    "\n",
    "print(\"GBR --> MSE = {}\".format(mseGBR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Faça um gráfico comparativo entre resultados das avaliações (Evaluation) dos modelos acima.\n",
    "Dica: o Notebook do seguinte link (https://github.com/ciencia-de-dados-pratica/GEAM/blob/master/001/iris-notebook.ipynb) pode servir de inspiração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD: 0.0443153206024\n",
      "LR: 0.029930497035\n",
      "LSVR: 0.031702333287\n",
      "SVR: 0.0297424114885\n",
      "RFR: 0.0301611029978\n",
      "GBR: 0.0294021709658\n"
     ]
    }
   ],
   "source": [
    "class_names = ['SGD','LR','LSVR','SVR','RFR','GBR']\n",
    "class_ = [mseSGD, mseLR, mseLSVR, mseSVR, mseRFR, mseGBR]\n",
    "for i in range(0,len(class_names)):\n",
    "    print(class_names[i] + ': ' + str(class_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7f5d59172be0>,\n",
       "  <matplotlib.axis.XTick at 0x7f5d591b1e48>,\n",
       "  <matplotlib.axis.XTick at 0x7f5d618302b0>,\n",
       "  <matplotlib.axis.XTick at 0x7f5d59123550>,\n",
       "  <matplotlib.axis.XTick at 0x7f5d59123ba8>,\n",
       "  <matplotlib.axis.XTick at 0x7f5d591302b0>],\n",
       " <a list of 6 Text xticklabel objects>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5d61587cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.grid()\n",
    "plt.bar(range(len(class_names)),class_)\n",
    "plt.xticks(range(len(class_names)), class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Escolha o melhor algoritmo obtido a partir de cross validation e treine um modelo usando o dataset completo, ou seja, gere um modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGBR = ensemble.GradientBoostingRegressor()\n",
    "modelGBR.fit(X_f, y_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Qual a diferença entre Stochastic Gradient Descent e Gradient Descent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos relativamente simples, ambos são métodos para atualizar um conjunto de parâmetros de maneira iterativa \n",
    "para minimizar uma função de erro. Com Gradient Descent, você usa todos os seus dados para calcular o \n",
    "gradiente; com Stochastic Gradient Descent você usa um subconjunto de seus dados. O SGD é muito mais rápido, embora \n",
    "a função de erro não seja tão bem minimizada."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
