{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold as sk, KFold\n",
    "from sklearn import metrics as m, neighbors as n\n",
    "import numpy as np\n",
    "from libs import knn as k, dist_metrics as dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. Crie os seguintes arquivos com extensão .py e implemente os métodos definidos para cada um deles:\n",
    "\n",
    "dist_metrics.py - medidas de distância (ver slides correspondentes). Implemente as medidas de distância a seguir:\n",
    "    \n",
    "    minkowski_distance(X, row, p)\n",
    "    euclidean_distance(X, row). Dica: usar minkowski_distance com p=2.\n",
    "    manhattan_distance(X, row). Dica: usar minkowski_distance com p=1.\n",
    "    chebyshev_distance(X, row)\n",
    "\n",
    "onde X é uma matriz e row é uma linha para calculo da distância entre X e esta linha (row).\n",
    "\n",
    "Veja exemplo de implementação da distância euclidiana neste jupyter notebook (https://github.com/regispires/aulas-machine-learning/blob/master/09-kNN.ipynb).\n",
    "\n",
    "https://sites.google.com/site/ufcregis/_/rsrc/1523541583132/home/2018-1/aprendizado-de-maquina/dist_metrics.png\n",
    "\n",
    "knn.py - implementações do knn para classificação e regressão. Você pode adaptar o exemplo do seguinte link (https://github.com/regispires/aulas-machine-learning/blob/master/09-kNN.ipynb) para tomar como base inicial para a sua implementação da regressão logística, que deve ter os métodos fit e predict. Explicação mais detalhada nos slides. Implemente as classes de acordo com as seguintes assinaturas:\n",
    "\n",
    "    KNNClassifier(k=5, metric='minkowski', p=2). Para detalhes sobre os parâmetros veja esta documentação do sklearn.\n",
    "    KNNRegressor(k=5, metric='minkowski', p=2). Para detalhes sobre os parâmetros veja esta documentação do sklearn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A classe do [[ 4.   2.5]] é: 0\n",
      "A predição do [[ 4.   2.5]] é: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Teste das classes e métricas\n",
    "X = np.array([[ 2.7810836 ,  2.550537  ],\n",
    "       [ 1.46548937,  2.36212508],  \n",
    "       [ 3.39656169,  4.40029353],  \n",
    "       [ 1.38807019,  1.85022032],  \n",
    "       [ 3.06407232,  3.00530597],  \n",
    "       [ 7.62753121,  2.75926224],\n",
    "       [ 5.33244125,  2.08862677],\n",
    "       [ 6.92259672,  1.77106367],\n",
    "       [ 8.67541865, -0.24206865],\n",
    "       [ 7.67375647,  3.50856301]])\n",
    "\n",
    "\n",
    "y = np.array([ 0,  0,  0,  0,  0,  1,  1,  1,  1,  1])\n",
    "\n",
    "model = k.KNNClassifier(3, 'minkowski', 2)\n",
    "model.fit(X, y)\n",
    "\n",
    "X_test = np.array([[4.0, 2.5]])\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(\"A classe do {} é: {}\".format(X_test, prediction))\n",
    "\n",
    "model = k.KNNRegressor(3, 'minkowski', 2)\n",
    "model.fit(X, y)\n",
    "\n",
    "X_test = np.array([[4.0, 2.5]])\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print(\"A predição do {} é: {}\".format(X_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Agora avalie e compare sua implementação de KNNClassifier usando a distância euclidiana e a distância manhattan. Compare seus resultados com a implementação do scikit learn somente para a distância euclidiana. \n",
    "\n",
    "Use o dataset winequality-white.csv em sua avaliação.\n",
    "\n",
    "Use o KFold Cross-Validation do Scikit Learn com k=3 (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html). Há um exemplo semelhante de uso neste jupyter notebook (https://github.com/regispires/aulas-machine-learning/blob/master/11-Stratified%20Split.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatando a entrada...\n"
     ]
    }
   ],
   "source": [
    "data = np.genfromtxt(\"winequality-white.csv\", delimiter=\",\")\n",
    "\n",
    "X = data[:,:11]\n",
    "y = data[:,11]\n",
    "\n",
    "train = sk(n_splits=3, shuffle=True, random_state=42)\n",
    "train.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in train.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "print(\"Formatando a entrada...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my KNNClassifier with manhattan: 0.03314917127071823\n"
     ]
    }
   ],
   "source": [
    "model_classifier_1 = k.KNNClassifier(3, 'manhattan')\n",
    "model_classifier_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1 = [model_classifier_1.predict(X_test[i]) for i in range(len(X_test))]\n",
    "\n",
    "#print(y_pred_1)\n",
    "\n",
    "print(\"Accuracy of my KNNClassifier with manhattan: {}\".format(m.accuracy_score(y_test, y_pred_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my KNNClassifier with euclidean: 0.39594843462246776\n"
     ]
    }
   ],
   "source": [
    "model_classifier_2 = k.KNNClassifier(3, 'euclidean')\n",
    "model_classifier_2.fit(X_train, y_train)\n",
    "\n",
    "y_pred_2 = [model_classifier_2.predict(X_test[i]) for i in range(len(X_test))]\n",
    "\n",
    "#print(y_pred)\n",
    "\n",
    "print(\"Accuracy of my KNNClassifier with euclidean: {}\".format(m.accuracy_score(y_test, y_pred_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Sklearn's KNNClassifier with euclidean: 0.47882136279926335\n"
     ]
    }
   ],
   "source": [
    "model_SK = n.KNeighborsClassifier(3, metric='euclidean')\n",
    "model_SK.fit(X_train, y_train)\n",
    "\n",
    "y_pred_SK = [model_SK.predict(np.array([X_test[i]])) for i in range(len(X_test))]\n",
    "\n",
    "print(\"Accuracy of Sklearn's KNNClassifier with euclidean: {}\".format(m.accuracy_score(y_test, y_pred_SK)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Agora avalie e compare sua implementação de KNNRegressor usando a distância euclidiana e a distância manhattan. Compare seus resultados com a implementação do scikit learn somente para a distância euclidiana. \n",
    "\n",
    "Use o dataset pima-indians-diabetes.csv em sua avaliação.\n",
    "\n",
    "Use o KFold Cross-Validation do Scikit Learn com k=5 (http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html). Há um exemplo semelhante de uso neste jupyter notebook (https://github.com/regispires/aulas-machine-learning/blob/master/11-Stratified%20Split.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatando a entrada...\n"
     ]
    }
   ],
   "source": [
    "train_ = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "train_.get_n_splits(X, y)\n",
    "\n",
    "for train_index_, test_index_ in train_.split(X, y):\n",
    "    #print(\"TRAIN:\", train_index_, \"TEST:\", test_index_)\n",
    "    X_train_, X_test_ = X[train_index_], X[test_index_]\n",
    "    y_train_, y_test_ = y[train_index_], y[test_index_]\n",
    "    \n",
    "print(\"Formatando a entrada...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of my KNNRegressor with manhattan: 1.5168539325842696\n"
     ]
    }
   ],
   "source": [
    "model_regressor_1 = k.KNNRegressor(5, 'manhattan')\n",
    "model_regressor_1.fit(X_train_, y_train_)\n",
    "\n",
    "y_pred_rg_1 = [model_regressor_1.predict(X_test_[i]) for i in range(len(X_test_))]\n",
    "\n",
    "#print(y_pred_1)\n",
    "\n",
    "print(\"MSE of my KNNRegressor with manhattan: {}\".format(m.mean_squared_error(y_test_, y_pred_rg_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of my KNNRegressor with euclidean: 0.7493769152196118\n"
     ]
    }
   ],
   "source": [
    "model_regressor_2 = k.KNNRegressor(5, 'euclidean')\n",
    "model_regressor_2.fit(X_train_, y_train_)\n",
    "\n",
    "y_pred_rg_2 = [model_regressor_2.predict(X_test_[i]) for i in range(len(X_test_))]\n",
    "\n",
    "#print(y_pred_1)\n",
    "\n",
    "print(\"MSE of my KNNRegressor with euclidean: {}\".format(m.mean_squared_error(y_test_, y_pred_rg_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of Sklearn's KNNRegressor with euclidean: 0.678896833503575\n"
     ]
    }
   ],
   "source": [
    "model_RG = n.KNeighborsRegressor(5, metric='euclidean')\n",
    "model_RG.fit(X_train_, y_train_)\n",
    "\n",
    "y_pred_RG = [model_RG.predict(np.array([X_test_[i]])) for i in range(len(X_test_))]\n",
    "\n",
    "\n",
    "print(\"MSE of Sklearn's KNNRegressor with euclidean: {}\".format(m.mean_squared_error(y_test_, y_pred_RG)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
